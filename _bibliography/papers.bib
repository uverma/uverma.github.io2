---
---

@string{aps = {ieee,}}


@INPROCEEDINGS{AshutoshConnect2022,
  author={B, Ashutosh Holla and M, Manohara Pai M. and Verma, Ujjwal and Pai, Radhika M.},
  booktitle={2022 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={Enhanced Vehicle Re-identification for ITS: A Feature Fusion approach using Deep Learning}, 
  year={2022},
  abbr ={CONECCT 2022},
  html = {https://ieeexplore.ieee.org/document/9865740},
  volume={},
  number={},
  pages={1-6},
  keywords={Computer vision;Fuses;Computational modeling;Lighting;Computer architecture;Transformers;Cameras;CCTV;Keyframes;re-identification;CNN;Transformer;Triplet Loss},
  doi={10.1109/CONECCT55679.2022.9865740}}

@article{lakaraevaluating,
  title={Evaluating Predictive Uncertainty and Robustness to Distributional Shift Using Real World Data},
  author={Lakara, Kumud and Bhandari, Akshat and Seth, Pratinav and Verma, Ujjwal},
  booktitle = {Bayesian Deep Learning at  Neural Information Processing Systems (NeurIPS) 2021},
  year = {2021},
  abbr ={BDL-NeurIPS 2021},
  html = {http://bayesiandeeplearning.org/2021/papers/17.pdf},
  pdf = {Kumud_NeurIPS2021.pdf},
  selected = {true},
  abstract = {Most machine learning models operate under the assumption that the training,
testing and deployment data is independent and identically distributed (i.i.d.).
This assumption does not generally hold true in a natural setting. Usually, the
deployment data is subject to various types of distributional shifts. The magnitude
of a model’s performance is proportional to this shift in the distribution of the
dataset. Thus it becomes necessary to evaluate a model’s uncertainty and robustness
to distributional shifts to get a realistic estimate of its expected performance on
real-world data. Present methods to evaluate uncertainty and model’s robustness are
lacking and often fail to paint the full picture. Moreover, most analysis so far has
primarily focused on classification tasks. In this paper, we propose more insightful
metrics for general regression tasks using the Shifts Weather Prediction Dataset.
We also present an evaluation of the baseline methods using these metrics}
}


@inproceedings{BERT-SMMH4H,
    title = "{BERT} based Transformers lead the way in Extraction of Health Information from Social Media",
    author = "Ramesh, Sidharth  and
      Tiwari, Abhiraj  and
      Choubey, Parthivi  and
      Kashyap, Saisha  and
      Khose, Sahil  and
      Lakara, Kumud  and
      Singh, Nishesh  and
      Verma, Ujjwal",
    booktitle = "Proceedings of the Sixth Social Media Mining for Health ({\#}SMM4H) Workshop and Shared Task",
    month = June,
    year = "2021",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2021.smm4h-1.5",
    doi = "10.18653/v1/2021.smm4h-1.5",
    pages = "33--38",
    pdf={Sidharth_NAACL-2021.pdf},
    html = {https://aclanthology.org/2021.smm4h-1.5/},
    abbr ={NAACL - SMM4H},
    selected={true},
    }

@INPROCEEDINGS{BhavamTENCON2021,
  author={Vidyarthi, Bhavam and Sequeira, Neil and Lenka, Sushant and Verma, Ujjwal},
  booktitle={TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)}, 
  title={Enhancement of PSNR based Anomaly Detection in Surveillance Videos using Penalty Modules}, 
  year={2021},
  volume={},
  number={},
  pages={805-810},
  abbr ={IEEE TENCON 2021},
  doi={10.1109/TENCON54134.2021.9707336}}


@INPROCEEDINGS{AshutoshTENCON2021,
  author={Ashutosh Holla, B and Manohara Pai, M.M. and Verma, Ujjwal and Pai, Radhika M.},
  booktitle={TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)}, 
  title={Vehicle Re-identification in Smart City Transportation using Hybrid Surveillance Systems}, 
  year={2021},
  volume={},
  number={},
  pages={335-340},
  abbr ={IEEE TENCON 2021},
  doi={10.1109/TENCON54134.2021.9707382}}



@INPROCEEDINGS{GirishaTENCON2021,
  author={S, Girisha and Pai,  Manohara and Verma, Ujjwal and Pai, Radhika M. and S, Shreesha},
  booktitle={TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)}, 
  title={Anomaly Detection Using Classification CNN Models: A Video Analytic Approach}, 
  year={2021},
  volume={},
  number={},
  pages={923-928},
  abbr ={IEEE TENCON 2021},
  doi={10.1109/TENCON54134.2021.9707202}}


@INPROCEEDINGS{AnanyaTENCON2021,
  author={Sharma, Ananya and Verma, Ujjwal},
  booktitle={TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)}, 
  title={Flood Magnitude Assessment from UAV Aerial Videos Based on Image Segmentation and Similarity}, 
  year={2021},
  volume={},
  number={},
  pages={476-481},
  abbr ={IEEE TENCON 2021},
  doi={10.1109/TENCON54134.2021.9707250}}
  
  
  
  @INPROCEEDINGS{ShreeshaTENCON2021,
  author={S, Shreesha and M, Manohara Pai M. and Verma, Ujjwal and Pai, Radhika M. and S, Girisha},
  booktitle={TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)}, 
  title={Behavioural Pattern Analysis of Fishes for Smart Aquaculture: An Object Centric Approach}, 
  year={2021},
  volume={},
  number={},
  pages={917-922},
  abbr ={IEEE TENCON 2021},
  doi={10.1109/TENCON54134.2021.9707293}}
  
  @INPROCEEDINGS{PranoyMysuru2021,
  author={Ghosh, Pranoy and Pai, Krithika M and M M, Manohara Pai and Verma, Ujjwal and Rivet, Frederic and Roul, Abhishek and Venugopal, V},
  booktitle={2021 IEEE Mysore Sub Section International Conference (MysuruCon)}, 
  title={Exploring Techniques for Photo-realistic Image Generation from 3D Models - A Deep Learning Approach}, 
  year={2021},
  volume={},
  number={},
  pages={697-702},
  abbr ={IEEE MysuruCon 2021},
  doi={10.1109/MysuruCon52639.2021.9641645}}
  
  @INPROCEEDINGS{ShreeshaCONNECT2021,
  author={S, Shreesha and M, Manohara Pai M and Pai, Radhika M and Verma, Ujjwal},
  booktitle={2021 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={LSTM-Based Prediction of Water Quality Parameters System in Backwaters}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abbr ={IEEE CONNECT 2021},
  doi={10.1109/CONECCT52877.2021.9622543}}
  
  @INPROCEEDINGS{GirishaMASCON2021,
  author={Girisha, S and Pai, Manohara M.M and Verma, Ujjwal and Pai, Radhika M.},
  booktitle={2021 IEEE Madras Section Conference (MASCON)}, 
  title={Semantic Segmentation with Enhanced Temporal Smoothness Using CRF in Aerial Videos}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abbr ={IEEE MASCON 2021},
  doi={10.1109/MASCON51689.2021.9563599}}





@article{Arjun-CAGEO21,
title = {DeepRivWidth : Deep learning based semantic segmentation approach for river identification and width measurement in SAR images of Coastal Karnataka},
journal = {Computers & Geosciences},
pages = {104805},
year = {2021},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2021.104805},
url = {https://www.sciencedirect.com/science/article/pii/S0098300421001059},
author = {Ujjwal Verma and Arjun Chauhan and Manohara Pai M.M. and Radhika Pai},
keywords = {Semantic segmentation, Synthetic Aperture Radar, River width measurement, Convolutional neural networks},
html ={https://www.sciencedirect.com/science/article/pii/S0098300421001059},
pdf={DeepRivWidth-Ujjwal2021.pdf},
abbr ={CAGEO},
}



@article{verma2020uvid,
  abbr={IEEE JSTARS},
  author={S Girisha* and Ujjwal Verma* and Pai, Manohara Pai and Radhika Pai},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={UVid-Net: Enhanced Semantic Segmentation of UAV Aerial Videos by Embedding Temporal Information}, 
  year={2021},
  volume={14},
  number={},
  pages={4115-4127},
  abstract={Semantic segmentation of aerial videos has been extensively used for decision making in monitoring environmental changes, urban planning, and disaster management. The reliability of these decision support systems is dependent on the accuracy of the video semantic segmentation algorithms. The existing CNN based video semantic segmentation methods have enhanced the image semantic segmentation methods by incorporating an additional module such as LSTM or optical flow for computing temporal dynamics of the video which is a computational overhead. The proposed research work modifies the CNN architecture by incorporating temporal information to improve the efficiency of video semantic segmentation. In this work, an enhanced encoder-decoder based CNN architecture (UVid-Net) is proposed for UAV video semantic segmentation. The encoder of the proposed architecture embeds temporal information for temporally consistent labelling. The decoder is enhanced by introducing the feature-refiner module, which aids in accurate localization of the class labels. The proposed UVid-Net architecture for UAV video semantic segmentation is quantitatively evaluated on extended ManipalUAVid dataset. The performance metric mIoU of 0.79 has been observed which is significantly greater than the other state-of-the-art algorithms. Further, the proposed work produced promising results even for the pre-trained model of UVid-Net on urban street scene with fine tuning the final layer on UAV aerial videos.},
   html={https://ieeexplore.ieee.org/document/9392319},
  selected={true},
  pdf = {UVidNet-JSTARS-2021.pdf},
 }
@article{prabhu2020thread,
  abbr ={RSC Adv.},
  title={Thread integrated smart-phone imaging facilitates early turning point colorimetric assay for microbes},
  author={Anusha Prabhu and Giri Nandagopal and Prakash Peralam Yegneswaran and Vijendra Prabhu  and Ujjwal Verma and Naresh Kumar Mani},
  journal={RSC Advances},
  volume={10},
  number={45},
  pages={26853--26861},
  year={2020},
  publisher={Royal Society of Chemistry},
  html ={https://pubs.rsc.org/en/content/articlehtml/2020/ra/d0ra05190j},
  pdf={Anusha-2020.pdf},  
  selected={true}
}

@article{shorewala2021weed,
  abbr={IEEE Access},
  title={Weed Density and Distribution Estimation for Precision Agriculture Using Semi-Supervised Learning},
  author={Shantam Shorewala and Armaan Ashfaque * and R Sidharth * and Ujjwal Verma},
  journal={IEEE Access},
  volume={9},
  pages={27971--27986},
  year={2021},
  publisher={IEEE},
  pdf={Shantam_Access-2021.pdf},
    }

@inproceedings{bhooshan2008t,
  title={T-Law: A new suggestion for signal companding},
  author={Sunil Bhooshan  and Vinay Kumar  and Ujjwal Verma and Hitesh Vatsyayan and Rohit Kumar},
  booktitle={2008 Congress on Image and Signal Processing},
  volume={3},
  pages={190--194},
  year={2008},
  organization={IEEE}
}

@inproceedings{boisgontier2014shape,
  abbr={ICPRAM},
  title={Shape-based segmentation of tomatoes for agriculture monitoring},
  author={Ujjwal Verma and Florence Rossant and Isabelle Bloch and Julien Orensanz and Denis Boisgontier},
  booktitle={International Conference on Pattern Recognition Applications and Methods (ICPRAM)},
  pages={402--411},
  year={2014},
  html={https://www.scitepress.org/Papers/2014/48188/pdf/index.html},
   pdf={ICPRAM_2014_72_CR.pdf}
}

@article{verma2015segmentation,
  abbr={EURASIP JIVP},
  title={Segmentation and size estimation of tomatoes from sequences of paired images},
  author={Ujjwal Verma and Florence Rossant and Isabelle Bloch},
  journal={EURASIP Journal on Image and Video Processing},
  volume={2015},
  number={1},
  pages={33},
  year={2015},
  publisher={Springer International Publishing},
  html={https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-015-0087-0},
  pdf={EURASIP_JIVP_Ujjwal.pdf},
  selected={true}
}

@incollection{verma2015segmentation2,
  title={Segmentation of tomatoes in open field images with shape and temporal constraints},
  author={Ujjwal Verma and Florence Rossant and Isabelle Bloch and Julien Orensanz and Denis Boisgontier},
  booktitle={Pattern Recognition Applications and Methods},
  pages={162--178},
  year={2015},
  publisher={Springer International Publishing},
  html={https://link.springer.com/chapter/10.1007/978-3-319-25530-9_11},
  pdf={LNCS-Ujjwal-15.pdf},
  }

@inproceedings{verma2014tomato,
  title={Tomato development monitoring in an open field, using a two-camera acquisition system},
  author={Ujjwal Verma and Florence Rossant and Isabelle Bloch and Julien Orensanz and Denis Boisgontier and Marthe Lagarrigue},
  booktitle={12th International Conference on Precision Agriculture},
  year={2014},
  pdf={ICPA2014-Ujjwal.pdf}
}

@inproceedings{pai2019automatic,
  title={Automatic segmentation of river and land in sar images: A deep learning approach},
  author={Manohara Pai  and Vaibhav Mehrotra  and Shreyas Aiyar and Ujjwal Verma and Radhika Pai},
  booktitle={2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)},
  pages={15--20},
  year={2019},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/8791719},
  pdf={AIKE-Vaibhav-2019.pdf},
   abstract={The ubiquitousness of satellite imagery and powerful, computationally efficient Deep Learning frameworks have found profound use in the field of remote sensing. Augmented with easy access to abundant image data made available by different satellites such as LANDSAT and European Space Agency's Copernicus missions, deep learning has opened various avenues of research in monitoring the world's oceans, land, rivers, etc. One significant problem in this direction is the accurate identification and subsequent segmentation of surface-water in images in the microwave spectrum. Typically, standard image processing tools are used to segment the images which are time-inefficient. However, in recent years, deep learning methods for semantic segmentation is the preferred choice given its high accuracy and ease of use. This paper proposes the use of deep-learning approaches such as U-Net to perform an efficient segmentation of river and land. Experimental results show that our approach achieves vastly superior performance on SAR images with pixel accuracy of 0.98 and F1 score of 0.99.},
}

@inproceedings{girisha2019semantic,
  title={Semantic segmentation of UAV aerial videos using convolutional neural networks},
  author={S. Girisha  and Manohara Pai  and Ujjwal Verma and Radhika Pai},
  booktitle={2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)},
  pages={21--27},
  year={2019},
  organization={IEEE},
  abstract={Semantic segmentation of complex aerial videos enables a better understanding of scene and context. This enhances the performance of automated video processing techniques like anomaly detection, object detection, event detection and other applications. But, there is a limited study of semantic segmentation in aerial videos due to non-availability of the relevant dataset. To address this, an aerial video dataset is captured using DJI Phantom 3 professional drone and is annotated manually. In addition, the proposed research work investigates the performance of semantic segmentation algorithms for aerial videos implemented using Fully Convolution Networks (FCN) and U-net architectures. In this study, two classes (greenery, road) are considered for semantic segmentation. It is observed that both architectures perform competitively on the aerial videos of Unmanned Aerial Vehicle (UAV) with a pixel accuracy of 89.7\% and 87.31\% respectively.},
   html={https://ieeexplore.ieee.org/document/8791701},
  pdf={AIKE-Girish-2019.pdf}
}

@article{girisha2019performance,
  abbr ={IEEE Access},
  title={Performance Analysis of Semantic Segmentation Algorithms for Finely Annotated New UAV Aerial Video Dataset (ManipalUAVid)},
  author={S Girisha and Manohara Pai and Ujjwal Verma  and Radhika Pai},
  journal={IEEE Access},
  volume={7},
  pages={136239--136253},
  year={2019},
  publisher={IEEE},
   abstract={Semantic segmentation of videos helps in scene understanding, thereby assisting in other automated video processing techniques like anomaly detection, object detection, event detection, etc. However, there has been limited study on semantic segmentation of videos acquired using Unmanned Aerial Vehicles (UAV), primarily due to the absence of standard dataset. In this paper, a new UAV aerial video dataset (ManipalUAVid) for semantic segmentation is presented. The videos have been acquired in a closed university campus, and fine annotation is provided for four background classes viz. constructions, greeneries, roads, and waterbodies. Also, the performance of four semantic segmentation approaches: Conditional Random Field (CRF), U-Net, Fully Convolutional Network (FCN) and DeepLabV3+ are analysed on ManipalUAVid dataset. It is seen that these algorithms perform competitively on UAV aerial video dataset and achieves an mIoU of 0.86, 0.86, 0.86 and 0.83 respectively},
   html={https://ieeexplore.ieee.org/document/8835008},
  pdf={IEEE_Access_GirishPgNb.pdf}
}

@article{pai2020improved,
  title={Improved Semantic Segmentation of Water Bodies and Land in SAR Images Using Generative Adversarial Networks},
  author={Manohara Pai and Vaibhav Mehrotra  and Ujjwal Verma and Radhika Pai},
  journal={International Journal of Semantic Computing},
  volume={14},
  number={01},
  pages={55--69},
  year={2020},
  publisher={World Scientific Publishing Company},
  abstract={The availability of computationally efficient and powerful Deep Learning frameworks and high-resolution satellite imagery has created new approach for developing complex applications in the field of remote sensing. The easy access to abundant image data repository made available by different satellites of space agencies such as Copernicus, Landsat, etc. has opened various avenues of research in monitoring the world’s oceans, land, rivers, etc. The challenging research problem in this direction is the accurate identification and subsequent segmentation of surface water in images in the microwave spectrum. In the recent years, deep learning methods for semantic segmentation are the preferred choice given its high accuracy and ease of use. One major bottleneck in semantic segmentation pipelines is the manual annotation of data. This paper proposes Generative Adversarial Networks (GANs) on the training data (images and their corresponding labels) to create an enhanced dataset on which the networks can be trained, therefore, reducing human effort of manual labeling. Further, the research also proposes the use of deep-learning approaches such as U-Net and FCN-8 to perform an efficient segmentation of auto annotated, enhanced data of water body and land. The experimental results show that the U-Net model without GAN achieves superior performance on SAR images with pixel accuracy of 0.98 and F1 score of 0.9923. However, when augmented with GANs, the results saw a rise in these metrics with PA of 0.99 and F1 score of 0.9954.},
  html={https://www.worldscientific.com/doi/abs/10.1142/S1793351X20400036},
  pdf={Vaibhav-IJSC_2020.pdf}
}






@inproceedings{shreesha2020computer,
  title={Computer Vision Based Fish Tracking And Behaviour Detection System},
  author={S Shreesha  and   Manohara Pai and Ujjwal Verma  and Radhika Pai},
  booktitle={2020 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)},
  pages={252--257},
  year={2020},
  organization={IEEE}
}

@inproceedings{holla2020efficient,
  title={Efficient Vehicle Counting by Eliminating Identical Vehicles in UAV aerial videos},
  author={Ashutosh Holla  and Manohara Pai and Ujjwal Verma  and Radhika Pai},
  booktitle={2020 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)},
  pages={246--251},
  year={2020},
  organization={IEEE}
}

@inproceedings{girisha2020semantic,
  title={Semantic Segmentation of UAV Videos based on Temporal Smoothness in Conditional Random Fields (BEST PAPER AWARD)},
  author={S. Girisha and Manohara Pai and Ujjwal Verma  and  Radhika Pai},
  booktitle={2020 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)},
  pages={241--245},
  year={2020},
  organization={IEEE}
}

